{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model class\n",
    "class LongShortTermMemoryModel:\n",
    "    def __init__(self, encoding_size):\n",
    "        # Model constants\n",
    "        cell_state_size = 128\n",
    "\n",
    "        # Cells\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(cell_state_size)\n",
    "\n",
    "        # Model input\n",
    "        self.batch_size = tf.placeholder(tf.int32, [])  # Needed by cell.zero_state call, and can be dependent on usage (training or generation)\n",
    "        self.x = tf.placeholder(tf.float32, [None, None, 26])  # Shape: [batch_size, max_time, encoding_size]\n",
    "        self.y = tf.placeholder(tf.float32, [None, None, 10])  # Shape: [batch_size, max_time, encoding_size]\n",
    "        self.in_state = cell.zero_state(self.batch_size, tf.float32)  # Can be used as either an input or a way to get the zero state\n",
    "\n",
    "        # Model variables\n",
    "        W = tf.Variable(tf.random_normal([cell_state_size, encoding_size]))\n",
    "        b = tf.Variable(tf.random_normal([encoding_size]))\n",
    "\n",
    "        # Model operations\n",
    "        lstm, self.out_state = tf.nn.dynamic_rnn(cell, self.x, initial_state=self.in_state)  # lstm has shape: [batch_size, max_time, cell_state_size]\n",
    "\n",
    "        # Logits, where tf.einsum multiplies a batch of txs matrices (lstm) with W\n",
    "        logits = tf.nn.bias_add(tf.einsum('bts,se->bte', lstm, W), b)  # b: batch, t: time, s: state, e: encoding\n",
    "\n",
    "        # Predictor\n",
    "        self.f = tf.nn.softmax(logits)\n",
    "\n",
    "        # Cross Entropy loss\n",
    "        self.loss = tf.losses.softmax_cross_entropy(self.y, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training set\n",
    "results = [\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # 'cat'\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],  # 'alien'\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],  # 'ghost'\n",
    "    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],  # 'bat'\n",
    "    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],  # 'panda'\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],  # 'kiwi'\n",
    "    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],  # 'wine'\n",
    "    [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],  # 'knife'\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],  # 'star'\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],  # 'rat'\n",
    "]\n",
    "\n",
    "# Encodes all letters a-z as input vector for model\n",
    "characters = dict()\n",
    "\n",
    "for i in range(97, 97+26):\n",
    "    characters[chr(i)] = [0 if not j == i-97 else 1 for j in range(26)]\n",
    "\n",
    "\n",
    "encoding_size = 10\n",
    "\n",
    "index_to_emoji = ['üò∫', 'üëΩ', 'üëª', 'ü¶á', 'üêº', 'ü•ù', 'üç∑', 'üî™', '‚≠ê', 'üêÄ']\n",
    "\n",
    "x_train = [\n",
    "    [characters[x] for x in 'cat'],\n",
    "    [characters[x] for x in 'alien'],\n",
    "    [characters[x] for x in 'ghost'],\n",
    "    [characters[x] for x in 'bat'],\n",
    "    [characters[x] for x in 'panda'],\n",
    "    [characters[x] for x in 'kiwi'],\n",
    "    [characters[x] for x in 'wine'],\n",
    "    [characters[x] for x in 'knife'],\n",
    "    [characters[x] for x in 'star'],\n",
    "    [characters[x] for x in 'rat'],\n",
    "]\n",
    "y_train = [\n",
    "    [results[0]],\n",
    "    [results[1]],\n",
    "    [results[2]],\n",
    "    [results[3]],\n",
    "    [results[4]],\n",
    "    [results[5]],\n",
    "    [results[6]],\n",
    "    [results[7]],\n",
    "    [results[8]],\n",
    "    [results[9]],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0910 17:28:49.821280 140478428444480 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0910 17:28:49.822058 140478428444480 deprecation.py:323] From <ipython-input-2-d002c39b2b25>:7: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0910 17:28:49.844995 140478428444480 deprecation.py:323] From <ipython-input-2-d002c39b2b25>:20: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0910 17:28:49.887013 140478428444480 deprecation.py:506] From /home/sindrtho/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0910 17:28:49.893953 140478428444480 deprecation.py:506] From /home/sindrtho/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0910 17:28:50.268056 140478428444480 deprecation.py:323] From /home/sindrtho/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0910 17:28:50.460371 140478428444480 deprecation.py:506] From /home/sindrtho/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Creating model and initializing session\n",
    "model = LongShortTermMemoryModel(encoding_size)\n",
    "\n",
    "# Training: adjust the model so that its loss is minimized\n",
    "minimize_operation = tf.train.RMSPropOptimizer(0.05).minimize(model.loss)\n",
    "\n",
    "# Create session object for running TensorFlow operations\n",
    "session = tf.Session()\n",
    "\n",
    "# Initialize tf.Variable objects\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "# Initialize model.in_state\n",
    "zero_state = session.run(model.in_state, {model.batch_size: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "# Trained an equal ammount of times on all emojis\n",
    "for epoch in range(500):\n",
    "    session.run(minimize_operation, {model.batch_size: 1, model.x: [x_train[epoch%10]], model.y: [y_train[epoch%10]], model.in_state: zero_state})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for predicting emoji from text\n",
    "def predict(text):\n",
    "    y = ''\n",
    "    state = session.run(model.in_state, {model.batch_size: 1})\n",
    "\n",
    "    for c in text:\n",
    "        y, state = session.run([model.f, model.out_state], {model.batch_size: 1, model.x: [[characters[c]]], model.in_state: state})\n",
    "\n",
    "    return index_to_emoji[y[0].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input a word:\tkiwi\n",
      "Program returns: ü•ù\n",
      "Please input a word:\tkiwis\n",
      "Program returns: ü•ù\n",
      "Please input a word:\tapples\n",
      "Program returns: üëΩ\n",
      "Please input a word:\tpanda\n",
      "Program returns: üêº\n",
      "Please input a word:\tknife\n",
      "Program returns: üî™\n",
      "Please input a word:\twine\n",
      "Program returns: üç∑\n",
      "Please input a word:\twinner\n",
      "Program returns: üç∑\n",
      "Please input a word:\tclear\n",
      "Program returns: üò∫\n",
      "Please input a word:\tls\n",
      "Program returns: ‚≠ê\n",
      "Please input a word:\taaa\n",
      "Program returns: üëΩ\n",
      "Please input a word:\ta\n",
      "Program returns: üëΩ\n",
      "Please input a word:\ts\n",
      "Program returns: ‚≠ê\n",
      "Please input a word:\td\n",
      "Program returns: üî™\n",
      "Please input a word:\tf\n",
      "Program returns: üî™\n",
      "Please input a word:\tg\n",
      "Program returns: üëª\n",
      "Please input a word:\th\n",
      "Program returns: ü•ù\n",
      "Please input a word:\tj\n",
      "Program returns: üî™\n",
      "Please input a word:\tk\n",
      "Program returns: ü•ù\n",
      "Please input a word:\tghooooost\n",
      "Program returns: üëª\n",
      "Please input a word:\tghost\n",
      "Program returns: üëª\n",
      "Please input a word:\tcaaaaaaaaat\n",
      "Program returns: üò∫\n",
      "Please input a word:\tcaaaaaaaaaatssssss\n",
      "Program returns: üò∫\n",
      "Please input a word:\texit\n",
      "\n",
      "Exiting program.\n"
     ]
    }
   ],
   "source": [
    "# Test program. Let's user input a string and prints the resulting emoji.\n",
    "text = input('Please input a word:\\t').split()[0].lower()\n",
    "while not text == 'exit':\n",
    "    print(\"Program returns:\", predict(text))\n",
    "    text = input('Please input a word:\\t').split()[0].lower()\n",
    "print('\\nExiting program.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
